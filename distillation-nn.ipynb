{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11cf1416",
   "metadata": {
    "papermill": {
     "duration": 0.003197,
     "end_time": "2025-03-09T10:27:41.716829",
     "exception": false,
     "start_time": "2025-03-09T10:27:41.713632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Knowledge Distillation with PyTorch (MNIST Classification)\n",
    "\n",
    "This repository implements **Knowledge Distillation** in PyTorch using the **MNIST dataset**. The goal is to train a **Student model** to achieve similar accuracy to a **Teacher model** while being significantly smaller and more efficient.\n",
    "\n",
    "## Overview\n",
    "\n",
    "* A **Teacher model** (larger network) is trained on MNIST.\n",
    "* A **Student model** (smaller network) learns from both the **Teacher's soft labels** and the ground-truth labels using **Distillation Loss**.\n",
    "* The **Student model** achieves **~97.68% accuracy**, nearly matching the **Teacher's 97.69% accuracy**, with **73.5% fewer parameters**.\n",
    "\n",
    "## Model Architectures\n",
    "\n",
    "| Model | Architecture (Fully Connected Layers) | Parameters | Accuracy (%) |\n",
    "|-------|--------------------------------------|------------|--------------|\n",
    "| **Teacher** | FC(784 → 1200) → FC(1200 → 1200) → FC(1200 → 10) | **2,395,210** | **97.69%** |\n",
    "| **Student** | FC(784 → 800) → FC(800 → 10) | **636,010** (**73.5% smaller**) | **97.68%** |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Train the Student Model with Distillation\n",
    "* Learns from **soft labels** (teacher's predictions) and **ground-truth labels**.\n",
    "* Uses **Distillation Loss**: $\\text{Loss} = \\alpha \\cdot \\text{KL-Divergence} + (1 - \\alpha) \\cdot \\text{CrossEntropyLoss}$\n",
    "* **Temperature (T=5.0)** controls softening of teacher logits.\n",
    "* **Alpha (α=0.7)** balances hard vs. soft targets.\n",
    "\n",
    "## Results\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "| Model | Accuracy (%) | Parameters | Size Reduction (%) |\n",
    "|-------|--------------|------------|---------------------|\n",
    "| **Teacher** | **97.69%** | **2,395,210** | - |\n",
    "| **Student** | **97.68%** | **636,010** | **73.5% smaller** |\n",
    "\n",
    "* **Minimal Accuracy Drop (~0.01%)**\n",
    "* **4x Reduction in Model Size**\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "* Hinton et al., \"Distilling the Knowledge in a Neural Network\" (2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0385122",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-09T10:27:41.723661Z",
     "iopub.status.busy": "2025-03-09T10:27:41.723265Z",
     "iopub.status.idle": "2025-03-09T10:27:42.616903Z",
     "shell.execute_reply": "2025-03-09T10:27:42.615881Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.899176,
     "end_time": "2025-03-09T10:27:42.618981",
     "exception": false,
     "start_time": "2025-03-09T10:27:41.719805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5092109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:27:42.625881Z",
     "iopub.status.busy": "2025-03-09T10:27:42.625410Z",
     "iopub.status.idle": "2025-03-09T10:27:51.994360Z",
     "shell.execute_reply": "2025-03-09T10:27:51.993327Z"
    },
    "papermill": {
     "duration": 9.374212,
     "end_time": "2025-03-09T10:27:51.996187",
     "exception": false,
     "start_time": "2025-03-09T10:27:42.621975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c8d124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:27:52.003250Z",
     "iopub.status.busy": "2025-03-09T10:27:52.002691Z",
     "iopub.status.idle": "2025-03-09T10:27:52.009769Z",
     "shell.execute_reply": "2025-03-09T10:27:52.008834Z"
    },
    "papermill": {
     "duration": 0.01278,
     "end_time": "2025-03-09T10:27:52.011913",
     "exception": false,
     "start_time": "2025-03-09T10:27:51.999133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 1200)\n",
    "        self.fc3 = nn.Linear(1200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0bd1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:27:52.022508Z",
     "iopub.status.busy": "2025-03-09T10:27:52.022194Z",
     "iopub.status.idle": "2025-03-09T10:27:52.027207Z",
     "shell.execute_reply": "2025-03-09T10:27:52.026310Z"
    },
    "papermill": {
     "duration": 0.011881,
     "end_time": "2025-03-09T10:27:52.028760",
     "exception": false,
     "start_time": "2025-03-09T10:27:52.016879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 800)\n",
    "        self.fc2 = nn.Linear(800, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657e125c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:27:52.035544Z",
     "iopub.status.busy": "2025-03-09T10:27:52.035143Z",
     "iopub.status.idle": "2025-03-09T10:27:57.154029Z",
     "shell.execute_reply": "2025-03-09T10:27:57.152892Z"
    },
    "papermill": {
     "duration": 5.123965,
     "end_time": "2025-03-09T10:27:57.155628",
     "exception": false,
     "start_time": "2025-03-09T10:27:52.031663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 13.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 352kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.27MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.92MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bcb5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:27:57.166011Z",
     "iopub.status.busy": "2025-03-09T10:27:57.165685Z",
     "iopub.status.idle": "2025-03-09T10:27:57.170581Z",
     "shell.execute_reply": "2025-03-09T10:27:57.169782Z"
    },
    "papermill": {
     "duration": 0.01143,
     "end_time": "2025-03-09T10:27:57.171938",
     "exception": false,
     "start_time": "2025-03-09T10:27:57.160508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher = F.softmax(teacher_logits / temperature, dim=1)\n",
    "    soft_student = F.log_softmax(student_logits / temperature, dim=1)\n",
    "    kl_div = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (temperature ** 2)\n",
    "    ce_loss = F.cross_entropy(student_logits, labels)\n",
    "    return alpha * kl_div + (1 - alpha) * ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe547608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:27:57.181832Z",
     "iopub.status.busy": "2025-03-09T10:27:57.181554Z",
     "iopub.status.idle": "2025-03-09T10:27:57.218385Z",
     "shell.execute_reply": "2025-03-09T10:27:57.217317Z"
    },
    "papermill": {
     "duration": 0.043703,
     "end_time": "2025-03-09T10:27:57.220209",
     "exception": false,
     "start_time": "2025-03-09T10:27:57.176506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher = TeacherModel()\n",
    "optimizer = optim.Adam(teacher.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b70a9dd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:27:57.231005Z",
     "iopub.status.busy": "2025-03-09T10:27:57.230696Z",
     "iopub.status.idle": "2025-03-09T10:33:46.358297Z",
     "shell.execute_reply": "2025-03-09T10:33:46.357273Z"
    },
    "papermill": {
     "duration": 349.134942,
     "end_time": "2025-03-09T10:33:46.360050",
     "exception": false,
     "start_time": "2025-03-09T10:27:57.225108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 1/5, Loss: 0.12028646469116211\n",
      "Teacher Epoch 2/5, Loss: 0.22822067141532898\n",
      "Teacher Epoch 3/5, Loss: 0.017489513382315636\n",
      "Teacher Epoch 4/5, Loss: 0.19024941325187683\n",
      "Teacher Epoch 5/5, Loss: 0.028011934831738472\n",
      "Student Epoch 1/5, Loss: 0.6762599945068359\n",
      "Student Epoch 2/5, Loss: 0.19092245399951935\n",
      "Student Epoch 3/5, Loss: 0.2055620551109314\n",
      "Student Epoch 4/5, Loss: 0.23702338337898254\n",
      "Student Epoch 5/5, Loss: 0.1306477189064026\n"
     ]
    }
   ],
   "source": [
    "def train_teacher(model, train_loader, optimizer, criterion, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Teacher Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "train_teacher(teacher, train_loader, optimizer, criterion)\n",
    "\n",
    "student = StudentModel()\n",
    "optimizer = optim.Adam(student.parameters(), lr=0.001)\n",
    "\n",
    "def train_student(student, teacher, train_loader, optimizer, temperature=5.0, alpha=0.7, epochs=5):\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            student_logits = student(data)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(data)\n",
    "            loss = distillation_loss(student_logits, teacher_logits, target, temperature, alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Student Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "train_student(student, teacher, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67dc08a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:33:46.372067Z",
     "iopub.status.busy": "2025-03-09T10:33:46.371737Z",
     "iopub.status.idle": "2025-03-09T10:33:51.539963Z",
     "shell.execute_reply": "2025-03-09T10:33:51.538838Z"
    },
    "papermill": {
     "duration": 5.176097,
     "end_time": "2025-03-09T10:33:51.541730",
     "exception": false,
     "start_time": "2025-03-09T10:33:46.365633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model Accuracy:\n",
      "Accuracy: 97.64%\n",
      "Student Model Accuracy:\n",
      "Accuracy: 97.51%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "print(\"Teacher Model Accuracy:\")\n",
    "teacher_accuracy = evaluate(teacher, test_loader)\n",
    "\n",
    "print(\"Student Model Accuracy:\")\n",
    "student_accuracy = evaluate(student, test_loader)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e5fa6b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T10:33:51.554208Z",
     "iopub.status.busy": "2025-03-09T10:33:51.553920Z",
     "iopub.status.idle": "2025-03-09T10:33:51.559289Z",
     "shell.execute_reply": "2025-03-09T10:33:51.558220Z"
    },
    "papermill": {
     "duration": 0.013397,
     "end_time": "2025-03-09T10:33:51.560939",
     "exception": false,
     "start_time": "2025-03-09T10:33:51.547542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model Parameters: 2395210\n",
      "Student Model Parameters: 636010\n",
      "Teacher Accuracy: 97.64%, Parameters: 2395210\n",
      "Student Accuracy: 97.51%, Parameters: 636010\n"
     ]
    }
   ],
   "source": [
    "teacher_params = count_parameters(teacher)\n",
    "student_params = count_parameters(student)\n",
    "\n",
    "print(f\"Teacher Model Parameters: {teacher_params}\")\n",
    "print(f\"Student Model Parameters: {student_params}\")\n",
    "\n",
    "print(f\"Teacher Accuracy: {teacher_accuracy:.2f}%, Parameters: {teacher_params}\")\n",
    "print(f\"Student Accuracy: {student_accuracy:.2f}%, Parameters: {student_params}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 374.216532,
   "end_time": "2025-03-09T10:33:53.289797",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-09T10:27:39.073265",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
